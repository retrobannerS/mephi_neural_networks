{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.050634</td>\n",
       "      <td>0.027240</td>\n",
       "      <td>-0.022914</td>\n",
       "      <td>0.037219</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>-0.032899</td>\n",
       "      <td>0.038020</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>-0.014699</td>\n",
       "      <td>-0.013311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>-0.005257</td>\n",
       "      <td>-0.006020</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>-0.010556</td>\n",
       "      <td>-0.002886</td>\n",
       "      <td>-0.004013</td>\n",
       "      <td>-0.002646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.082828</td>\n",
       "      <td>0.112354</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>-0.003085</td>\n",
       "      <td>-0.008792</td>\n",
       "      <td>-0.051937</td>\n",
       "      <td>0.034442</td>\n",
       "      <td>0.018615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021127</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>-0.006346</td>\n",
       "      <td>-0.005416</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>-0.005464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042588</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.008672</td>\n",
       "      <td>-0.049124</td>\n",
       "      <td>-0.006528</td>\n",
       "      <td>-0.016737</td>\n",
       "      <td>-0.026704</td>\n",
       "      <td>-0.066970</td>\n",
       "      <td>-0.001077</td>\n",
       "      <td>0.058637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005165</td>\n",
       "      <td>-0.002685</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.001146</td>\n",
       "      <td>-0.007280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.042608</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.008685</td>\n",
       "      <td>-0.049140</td>\n",
       "      <td>-0.006525</td>\n",
       "      <td>-0.016723</td>\n",
       "      <td>-0.026691</td>\n",
       "      <td>-0.066956</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>0.058653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005121</td>\n",
       "      <td>-0.002631</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>-0.002150</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.001166</td>\n",
       "      <td>-0.007277</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005453</td>\n",
       "      <td>-0.084841</td>\n",
       "      <td>-0.021381</td>\n",
       "      <td>-0.010569</td>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>-0.043900</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>-0.095431</td>\n",
       "      <td>-0.005969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005556</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.010339</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>-0.001127</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>-0.010629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.050634  0.027240 -0.022914  0.037219  0.018378 -0.032899  0.038020   \n",
       "1 -0.082828  0.112354  0.009881  0.012665  0.008541 -0.003085 -0.008792   \n",
       "2 -0.042588  0.001930  0.008672 -0.049124 -0.006528 -0.016737 -0.026704   \n",
       "3 -0.042608  0.001906  0.008685 -0.049140 -0.006525 -0.016723 -0.026691   \n",
       "4 -0.005453 -0.084841 -0.021381 -0.010569  0.012817  0.006240 -0.043900   \n",
       "\n",
       "         7         8         9  ...        41        42        43        44  \\\n",
       "0  0.007106 -0.014699 -0.013311 ... -0.004743  0.000467 -0.005257 -0.006020   \n",
       "1 -0.051937  0.034442  0.018615 ... -0.021127  0.002920  0.002466 -0.006346   \n",
       "2 -0.066970 -0.001077  0.058637 ... -0.005165 -0.002685  0.001238 -0.000939   \n",
       "3 -0.066956 -0.001069  0.058653 ... -0.005121 -0.002631  0.001206 -0.001003   \n",
       "4  0.008502 -0.095431 -0.005969 ... -0.005556 -0.000033 -0.000223 -0.010339   \n",
       "\n",
       "         45        46        47        48        49  50  \n",
       "0 -0.005111 -0.010556 -0.002886 -0.004013 -0.002646   1  \n",
       "1 -0.005416  0.005263  0.001795 -0.001875 -0.005464   1  \n",
       "2 -0.002155  0.004361 -0.000085 -0.001146 -0.007280   1  \n",
       "3 -0.002150  0.004290 -0.000087 -0.001166 -0.007277   1  \n",
       "4  0.001835 -0.001127 -0.004829  0.001877 -0.010629   1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(filepath_or_buffer='../all_data.csv', header=None, indexcol=0)\n",
    "FEATURES_INDEX = np.arange(2)\n",
    "LABELS_INDEX = 2\n",
    "BATCH_SIZE = int(0.6*all_data)\n",
    "LOSS_THRESHOLD = 1e-6\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>-0.023177</td>\n",
       "      <td>-0.034199</td>\n",
       "      <td>-0.071174</td>\n",
       "      <td>0.034209</td>\n",
       "      <td>-0.055537</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.085029</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>-0.022024</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.003055</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.005397</td>\n",
       "      <td>-0.003612</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>-0.004931</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>-0.068698</td>\n",
       "      <td>0.057827</td>\n",
       "      <td>0.062494</td>\n",
       "      <td>-0.120875</td>\n",
       "      <td>-0.031199</td>\n",
       "      <td>-0.126144</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.027971</td>\n",
       "      <td>0.042212</td>\n",
       "      <td>-0.037903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>-0.002963</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.001545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>-0.022014</td>\n",
       "      <td>-0.018537</td>\n",
       "      <td>-0.052204</td>\n",
       "      <td>-0.010769</td>\n",
       "      <td>-0.049487</td>\n",
       "      <td>0.042335</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>-0.026063</td>\n",
       "      <td>-0.004448</td>\n",
       "      <td>-0.008374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015350</td>\n",
       "      <td>-0.018111</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>-0.003928</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>-0.027492</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>-0.047973</td>\n",
       "      <td>-0.013806</td>\n",
       "      <td>-0.009351</td>\n",
       "      <td>-0.009311</td>\n",
       "      <td>-0.024605</td>\n",
       "      <td>-0.013044</td>\n",
       "      <td>0.041648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009767</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>-0.005193</td>\n",
       "      <td>-0.005427</td>\n",
       "      <td>-0.004483</td>\n",
       "      <td>-0.003516</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>-0.053112</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>-0.010851</td>\n",
       "      <td>-0.040524</td>\n",
       "      <td>-0.143514</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>-0.028555</td>\n",
       "      <td>0.030408</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005770</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>-0.001323</td>\n",
       "      <td>-0.000568</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>-0.000813</td>\n",
       "      <td>-0.002720</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "2708 -0.023177 -0.034199 -0.071174  0.034209 -0.055537  0.050054  0.085029   \n",
       "2709 -0.068698  0.057827  0.062494 -0.120875 -0.031199 -0.126144 -0.001503   \n",
       "2710 -0.022014 -0.018537 -0.052204 -0.010769 -0.049487  0.042335  0.060547   \n",
       "2711 -0.027492 -0.037501 -0.001082 -0.047973 -0.013806 -0.009351 -0.009311   \n",
       "2712 -0.053112  0.017851 -0.001592 -0.010851 -0.040524 -0.143514  0.026496   \n",
       "\n",
       "            7         8         9  ...        41        42        43  \\\n",
       "2708 -0.002683 -0.022024  0.001740 ... -0.000197 -0.003055  0.006381   \n",
       "2709 -0.027971  0.042212 -0.037903 ...  0.007117 -0.001194 -0.000628   \n",
       "2710 -0.026063 -0.004448 -0.008374 ... -0.015350 -0.018111  0.004594   \n",
       "2711 -0.024605 -0.013044  0.041648 ...  0.009767  0.000280  0.005480   \n",
       "2712 -0.028555  0.030408  0.003770 ... -0.005770  0.001425 -0.000558   \n",
       "\n",
       "            44        45        46        47        48        49  50  \n",
       "2708 -0.000235 -0.005397 -0.003612 -0.000170 -0.004931  0.000354   0  \n",
       "2709 -0.002963  0.001091  0.002984  0.002117 -0.000214 -0.001545   0  \n",
       "2710  0.017790 -0.003928  0.013328  0.001513  0.000267  0.002323   0  \n",
       "2711 -0.005193 -0.005427 -0.004483 -0.003516 -0.003058  0.003073   0  \n",
       "2712 -0.001323 -0.000568  0.003484 -0.000813 -0.002720  0.002752   0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_dataset = dataset[dataset[LABELS_INDEX] == 1]\n",
    "nonspam_dataset = dataset[dataset[LABELS_INDEX] == 0]\n",
    "nonspam_dataset.reset_index(drop=True, inplace=True)\n",
    "spam_dataset.reset_index(drop=True, inplace=True)\n",
    "nonspam_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621 1311 438 4370 4370\n"
     ]
    }
   ],
   "source": [
    "rand_indxs_spam = np.arange(len(spam_dataset))\n",
    "rand_indxs_nonspam = np.arange(len(nonspam_dataset))\n",
    "np.random.shuffle(rand_indxs_nonspam)\n",
    "np.random.shuffle(rand_indxs_spam)\n",
    "\n",
    "spam_f_threshold = int(len(spam_dataset)*0.6)\n",
    "spam_s_threshold = int(len(spam_dataset)*0.9)\n",
    "\n",
    "nonspam_f_threshold = int(len(nonspam_dataset)*0.6)\n",
    "nonspam_s_threshold = int(len(nonspam_dataset)*0.9)\n",
    "\n",
    "learn_dataset = pd.concat([spam_dataset.iloc[rand_indxs_spam[:spam_f_threshold]],\n",
    "                          nonspam_dataset.iloc[rand_indxs_nonspam[:nonspam_f_threshold]]])\n",
    "\n",
    "valid_dataset = pd.concat([spam_dataset.iloc[rand_indxs_spam[spam_f_threshold:spam_s_threshold]],\n",
    "                          nonspam_dataset.iloc[rand_indxs_nonspam[nonspam_f_threshold:nonspam_s_threshold]]])\n",
    "\n",
    "test_dataset = pd.concat([spam_dataset.iloc[rand_indxs_spam[spam_s_threshold:]],\n",
    "                         nonspam_dataset.iloc[rand_indxs_nonspam[nonspam_s_threshold:]]])\n",
    "\n",
    "print(len(learn_dataset), len(valid_dataset), len(test_dataset), len(learn_dataset)+len(valid_dataset)+len(test_dataset), len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_dataset = np.array(learn_dataset)\n",
    "valid_dataset = np.array(valid_dataset)\n",
    "test_dataset = np.array(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_dataloader = DataLoader(learn_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lin1): Linear(in_features=50, out_features=20, bias=True)\n",
       "  (lin2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (lin3): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (lin4): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin1 = nn.Linear(50, 20)\n",
    "        self.lin2 = nn.Linear(20, 10)\n",
    "        self.lin3 = nn.Linear(10, 10)\n",
    "        self.lin4 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.lin1(x))\n",
    "        x = F.tanh(self.lin2(x))\n",
    "        x = F.sigmoid(self.lin3(x))\n",
    "        x = F.sigmoid(self.lin4(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_load = False\n",
    "if is_load:\n",
    "    net.load_state_dict(torch.load('gd/net_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50])\n",
      "torch.Size([20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1])\n",
      "tensor([ 0.1057, -0.0200, -0.0698, -0.0589, -0.1443, -0.0311, -0.1970,\n",
      "         0.0359, -0.2930,  0.5696,  0.0542,  0.1223,  0.0284,  0.0047,\n",
      "         0.4658,  0.1139,  0.0917,  0.0071,  0.1144,  0.2354])\n"
     ]
    }
   ],
   "source": [
    "#Инициализация весов\n",
    "STD = [(2/(50+20+1))**(1/2), (2/(20+10+1))**(1/2), (32/(10+10+1))**(1/2), (32/(10+1+1))**(1/2)]\n",
    "null_weigth = []\n",
    "STD.reverse()\n",
    "\n",
    "def get_weights(layer):\n",
    "    if (type(layer) == nn.Linear):\n",
    "        cur_std = STD.pop()\n",
    "        null_weigth.append(torch.randn(layer.weight.data.shape)*cur_std)\n",
    "        null_weigth.append(torch.randn(layer.bias.data.shape)*cur_std)\n",
    "\n",
    "net.apply(get_weights)\n",
    "for k in null_weigth:\n",
    "    print(k.shape)\n",
    "print(null_weigth[1])\n",
    "null_weigth.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.1057, -0.0200, -0.0698, -0.0589, -0.1443, -0.0311, -0.1970,\n",
       "         0.0359, -0.2930,  0.5696,  0.0542,  0.1223,  0.0284,  0.0047,\n",
       "         0.4658,  0.1139,  0.0917,  0.0071,  0.1144,  0.2354])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_null_weigth = list(null_weigth)\n",
    "\n",
    "def init_weigths(layer):\n",
    "    if(type(layer) == nn.Linear):\n",
    "        layer.weight.data = (tmp_null_weigth.pop()).clone()\n",
    "        layer.bias.data = (tmp_null_weigth.pop()).clone()\n",
    "        \n",
    "net.apply(init_weigths)\n",
    "net.lin1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([1311])) that is different to the input size (torch.Size([1311, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "lr:  0.1  breaked on epoch:  11 \n",
      "\n",
      "0.0\n",
      "lr:  0.01  breaked on epoch:  11 \n",
      "\n",
      "0.0\n",
      "lr:  0.001  breaked on epoch:  11 \n",
      "\n",
      "0.0\n",
      "lr:  0.0001  breaked on epoch:  11 \n",
      "\n",
      "0.0\n",
      "lr:  1e-05  breaked on epoch:  11 \n",
      "\n",
      "CPU times: user 5.78 s, sys: 92.8 ms, total: 5.87 s\n",
      "Wall time: 4.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn_loss_by_lr = []\n",
    "valid_loss_by_lr = []\n",
    "test_loss_by_lr = []\n",
    "epoch_loss_by_lr = []\n",
    "lr_list = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "for lr in lr_list:\n",
    "    optimizer = optim.Rprop(net.parameters(), lr=lr)\n",
    "    \n",
    "    tmp_null_weigth = list(null_weigth)\n",
    "    net.apply(init_weigths)\n",
    "    \n",
    "    learn_epoch_loss = []\n",
    "    valid_epoch_loss = []\n",
    "    test_epoch_loss = []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        loss_acc = []\n",
    "        for learn_data in learn_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            features, labels = learn_data[:, FEATURES_INDEX].float(), learn_data[:, LABELS_INDEX].float()\n",
    "            features.requres_grad = True\n",
    "            labels.requres_grad = True\n",
    "            outputs = net(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_acc.append(float(loss.data))\n",
    "        learn_epoch_loss.append(np.mean(loss_acc))\n",
    "        \n",
    "        #критерий останова\n",
    "        if (epoch > 10) and\\\n",
    "        (abs(learn_epoch_loss[len(learn_epoch_loss) - 3] - learn_epoch_loss[len(learn_epoch_loss) - 4]) < LOSS_THRESHOLD) and\\\n",
    "        (abs(learn_epoch_loss[len(learn_epoch_loss) - 2] - learn_epoch_loss[len(learn_epoch_loss) - 3]) < LOSS_THRESHOLD) and\\\n",
    "        (abs(learn_epoch_loss[len(learn_epoch_loss) - 1] - learn_epoch_loss[len(learn_epoch_loss) - 2]) < LOSS_THRESHOLD):\n",
    "            print(learn_epoch_loss[len(learn_epoch_loss) - 1] - learn_epoch_loss[len(learn_epoch_loss) - 2])\n",
    "            print('lr: ', lr, ' breaked on epoch: ', epoch, '\\n')\n",
    "            break\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "            epoch_list.append(epoch)\n",
    "            for valid_data in valid_dataloader:\n",
    "                features, labels = valid_data[:, FEATURES_INDEX].float(), valid_data[:, LABELS_INDEX].float()\n",
    "                outputs = net(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_epoch_loss.append(float(loss.data))\n",
    "                \n",
    "            for test_data in valid_dataloader:\n",
    "                features, labels = test_data[:, FEATURES_INDEX].float(), test_data[:, LABELS_INDEX].float()\n",
    "                outputs = net(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_epoch_loss.append(float(loss.data))\n",
    "                \n",
    "    learn_loss_by_lr.append(learn_epoch_loss)\n",
    "    valid_loss_by_lr.append(valid_epoch_loss)\n",
    "    test_loss_by_lr.append(test_epoch_loss)\n",
    "    epoch_loss_by_lr.append(epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11eb50da0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xt0XOV57/Hvo5FkXSzrYku+ycYGgTEOYIggOLQ0kALGh5q0BWJoCMQGc20SDj1JTtuEhKympE3DSeKEFDAFEoIbCLc0hEsuqyRNuNhggvFNwjZYtmVdLcm6a+Y5f8y2I8uSPdaMNNLM77OW1szs/c7ez5a9nnn17nee19wdERFJHxnJDkBEREaXEr+ISJpR4hcRSTNK/CIiaUaJX0QkzSjxi4ikGSV+GdfMbIeZ/fkYiGOOmbmZZSY7FpGjUeIXEUkzSvwigzCzULJjEBkpSvySMswsw8y+YGbvmlmjmf3YzEr67X/czGrNrMXMXjazBf32PWRm95rZc2bWDpwfbPuumf3MzNrM7FUzOyHGWGaY2bNm1mRm1WZ2Q799Z5vZWjNrNbO9ZvbNYHuOmf0wiH2fmb1uZlMT+CsSAZT4JbV8GvgY8GfADKAZ+G6//T8HTgTKgDeARwe8/2rgn4AC4LfBtquArwDFQHWwPxaPATVBHJcDXzOzjwb7vgV8y90nAScAPw62XwsUArOAycBNQGeM5xOJmRK/pJIbgX9w9xp37wa+DFx+4Iaruz/o7m399p1uZoX93v+Mu/+Pu0fcvSvY9qS7v+bufUQ/KBYeLQgzmwX8CfB5d+9y9/XAA8A1QZNeoMLMprj7fnd/pd/2yUCFu4fdfZ27tw7/1yEyOCV+SSXHAU8FwyT7gE1AGJhqZiEzuzsYBmoFdgTvmdLv/TsHOWZtv+cdwMQY4pgBNLl7W79t7wEzg+crgJOAzcFwzqXB9h8ALwBrzGy3mf2LmWXFcD6RY6LEL6lkJ3CJuxf1+8lx911Eh3EuA/6c6HDKnOA91u/9iSpVuxsoMbOCfttmA7sA3L3K3a8iOuT0deAJM8t39153/4q7nwJ8GLgU+GSCYhI5SIlfUsn3gX8ys+MAzKzUzC4L9hUA3UAjkAd8baSCcPedwO+Afw5u2J5GtJf/aBDXJ8ys1N0jwL7gbWEzO9/MTg1mFLUSHfoJj1Sckr6U+CWVfAt4FnjRzNqAV4APBfseITrcsgvYGOwbSVcR/atiN/AUcKe7vxTsWwy8Y2b7g5iXBfcUpgFPEE36m4D/Bn44wnFKGjItxCIikl7U4xcRSTNK/CIiaUaJX0QkzSjxi4ikmTFZQnbKlCk+Z86cZIchIjJurFu3rsHdS2NpOyYT/5w5c1i7dm2ywxARGTfM7L1Y22qoR0QkzSjxi4ikGSV+EZE0o8QvIpJmlPhFRNLMURO/mc0ys1+b2SYze8fMPhNsLzGzl8ysKngsHuL91wZtqszs2kRfgIiIHJtYevx9wB3uPh84B7jVzE4BvgD80t1PBH4ZvD5EsN7pnUQrJJ4N3DnUB4SIiIyOoyZ+d9/j7m8Ez9uIloudSXRRi4eDZg8TXet0oIuBl9y9yd2bgZeIlqQd9yKdnTQ/9hiRjo5khyIickyOaYzfzOYAZwCvAlPdfQ9EPxyIriY00EwOXc6uhj8uPzfw2CvNbK2Zra2vrz+WsJJi/3+/TO1X7mLnTTcr+YvIuBJz4jezicBPgM8ewwLQNsi2QRcAcPf73L3S3StLS2P61nFStW7bAkDH2rVK/iIyrsSU+IMFn38CPOruTwab95rZ9GD/dKBukLfWALP6vS4nuiLRuLdr8zqa8+HRy6dEk/+NNyn5i8i4EMusHgNWA5vc/Zv9dj0LHJilcy3wzCBvfwG4yMyKg5u6FwXbxr3Izhpqi+FX83t56K8m0bFuHTtX3kikvT3ZoYmIHFEsPf5zgWuAC8xsffCzBLgbuNDMqoALg9eYWaWZPQDg7k3AV4HXg5+7gm3jXvaeJlpK83ho8UO8dloO9/9lPu1vrOP9G5X8RWRsO2p1Tnf/LYOP1QN8dJD2a4Hr+71+EHhwuAGORZHOTvL2ddE3YzYnFZ/EI4sf4YbQDXw/0sdNz7zB+zfeyOx//3cy8vOTHaqIyGH0zd1h6NkZnagUmlUOwKxJs3jkkkfYec5xrLosk4433lTPX0TGLCX+YWgJZvRMnHPCwW1leWU8tPghWv70VL611KLJf+WNhPcr+YvI2KLEPwwNW98GYEpPNTRtP7i9cEIh9194P37Bh7lnKXS8+QY7V65U8heRMUWJfxjad1TTmguzqp6Fe8+F1x8Aj349IS8rj1UfXUXB4ou5Z6nRvv5NJX8RGVOU+Ieh7/3oVM7ysMOss+Bnd8APPgb7omP/2aFs/vW8f2Xm0iu457Jo8n//husJ79+f5MhFRJT4hyVrTyP7ikPkFs2Ga56GS++Bna/DvR+GN34A7oQyQty56E4WXH4991xmdLz1Fu9fr+QvIsmnxH+MIj095DV10FsITDkJzKByOdzyO5h2Gjx7G/zoSmjdg5lx+wdvZ9HV/zva8//DH3hvxQolfxFJKiX+Y9Rbs4sMh1B+N0w58Y87iufAtT+FxV+H7b+B750Df/gxuLPi1BUs/tRX+H8fy6Dj7bfZvvxThNvaknYNIpLelPiP0YHibHl53TD5xEN3ZmTAOTfBTb+N/jXw5A3wn5+A/XVcftLlXLHy3/jWX2bStWED25Zfp+QvIkmhxH+MGqqCqZx5vdHkPpgpFbD8ebjwLqh6Kdr7f+cpLp5zMZ+65ft8969z6H5nI+9+6pNK/iIy6pT4j1Hb9io6JsDMzN5Dh3oGygjBuZ+BG1+Gotnw+HXw+Kf4cNE8bvzb/+DeK/Lp2biZqms/Qbg11irXIiLxU+I/Rr3v76S2GGZnTYS8yUd/Q9nJsOIXcP4/wqafwvfOYWHTLj7z2R9x/8eL6N28lS3XXq3kLyKjRon/GGXuaaC5KIO8khOjM3piEcqEP/s/sPLXMHEqrLmak379b/zdLQ/w8NVlhLe8y6ZPLlPyF5FRocR/DLyvj/z6dronRYYe3z+SaafCDb+C8z4Hbz/OrEf+ms//5af50TUz8a3b2fCJKwi3tCQ+cBGRfpT4j0Hvnj2EIk7GxN7oDdzhyMyGC/4Brv8F5BRS+vhyvjC/gp9cO4eM6vd562/+WslfREaUEv8xaNu2FYC8/CPM6InVzDNh5X/DuZ+h8K3/5HPZO/nZJ2eTuX0Xb179MSV/ERkxsSy9+KCZ1ZnZhn7b/rPfalw7zGz9EO/dYWZvB+3WJjLwZKjf+gcAJuf34MUV7NrSTNOedsJ9keEdMCsnOuVz+QvkhbL5312v8KsrJ5O9o5a1H7+UvubmBEYvIhJ11BW4gIeAVcAjBza4+8cPPDezfwOO1D09390bhhvgWNK6fSvZmTAzO8L7e4v4r++9CYBlGIWluRRPywt+8ikKHifkxvArnnU23PRbsn95F3/76r088BezWPTTBl5b9r84a81/kVVcMsJXJiLpJJalF182szmD7QsWYr8SuCCxYY1Nve/vpLkYzi2YyZbdnQCcf83JtNZ30ry3g+Y97bz3diORiB98T15hNsXT8g9+IBx4zC/KxvrPCsrOg0vuJjT/UlY+fTM/vLiL019o5tUrL6Fyzc/ImTxltC9XRFJULD3+I/lTYK+7Vw2x34EXzcyBf3f3+4Y6kJmtBFYCzJ49O86wRkZodz1NRcbEKfNoru0gvzCbU86dcUibcDgS/SCo7WBf8GHQvLeDra/W0tMVPtgua0LokL8OSoLHwlkfJnTz77nmpS/ypD/JCS/Cq1dexAd//BwTJ08b7UsWkRQUb+K/CnjsCPvPdffdZlYGvGRmm9395cEaBh8K9wFUVlb6YG2Opqv3j4nVDAwLHg9sM+zAvljn4B+ILxIhv66NrtMjMLmC5nXtFE8/fDH1UCgj6Nkfus/d6Wjtobn2jx8GzXva2bW1mS2v1h5sl5FhTCrNpXjap5h+2l+wxX/AjN/v4ZUrLuWDP/xPimecMPCUIiLHZNiJ38wygb8CPjhUG3ffHTzWmdlTwNnAoIk/ERbe9SJdvcd+o/XAh8MhHwwHPi6CfVM6m3mgz7GCPv7xNz1Mbmhlc06Ef7zzhfiCzoasUigKG0V9UBw2ivbtp6ihncIwhLiG+jOiTau/tBnYHN/5RGTMCoXbuOE/lo34eeLp8f85sNndawbbaWb5QIa7twXPLwLuiuN8R3XHhfPojUQOrIKIu//xOdHVER0PHjnQaMh9B7bhUFTVBEDuxD6OP/5MOuuN408oZuZxeSNyLQ7sizgZHWFC+/soevd/yK5rGpFzicgYEeobldMcNfGb2WPAR4ApZlYD3Onuq4FlDBjmMbMZwAPuvgSYCjwVDKlkAj9y9+cTG/6hbjjv+BE79uaHfokDxXk9LFr4IX766jY+ceEJzJxXPGLnPNSZo3QeEUl1sczquWqI7dcNsm03sCR4vg04Pc74xozWbVvJzYCZBbk0N4UABh3jFxEZ6/TN3Rj1vP8ee4tgVsnxNNe2MyEvk9yCrGSHJSJyzJT4Y5Sxq47GYpg05SSaazsonpZ/zDODRETGAiX+GLg7+Xtb6QyqcjbXtlM8fWRu6oqIjDQl/hiEGxrI7olgBWG68k6ks633sHn6IiLjhRJ/DPZvrwYgZ2IfTeHot4qLp6nHLyLjkxJ/DOqCBdaL8sM0d0wCoEQzekRknFLij0HLu5sJG8woK6V5bzeZWRkUlOQkOywRkWFR4o9B93s7qC+E2ZMraK5tp2haHpahGT0iMj4p8cfAdu2lsQgKS+fTvKdDN3ZFZFxT4j8KdyevtoWOwgg9hfNoa+qiRFM5RWQcU+I/ivC+feR0hfGCCPuYC6Aev4iMa0r8R9GxYxsQncrZ3FUKKPGLyPimxH8Ue6veAqCwKIvmJouur1uWm+SoRESGT4n/KPZVbyYCTJ8xk+baDgpLcwll6tcmIuOXMthRdL23naZJMLssqNGjb+yKyDinxH8UVrOb+iIomLyAlrpO1eAXkXFPif8ocmtb6SiM0Bo6iUjEKVGPX0TGuaMmfjN70MzqzGxDv21fNrNdZrY++FkyxHsXm9kWM6s2sy8kMvDREN6/n7z2PrwgQnPfTECrbonI+BdLj/8hYPEg2+9x94XBz3MDd5pZCPgucAlwCnCVmZ0ST7CjrTOYypk9MUxzWzThF01Vj19ExrejJn53fxloGsaxzwaq3X2bu/cAa4DLhnGcpNm7NTqVc1JZIc17O5lYPIHsnKMuUywiMqbFM8Z/m5n9IRgKKh5k/0xgZ7/XNcG2QZnZSjNba2Zr6+vr4wgrcZqqNwIwvXxWdLlFDfOISAoYbuK/FzgBWAjsAf5tkDaDla/0oQ7o7ve5e6W7V5aWlg4zrMTq2rGN5nwon7ZAUzlFJGUMK/G7+153D7t7BLif6LDOQDXArH6vy4Hdwzlf0uzcRX0xZOedTl9PRKUaRCQlDCvxm9n0fi//EtgwSLPXgRPNbK6ZZQPLgGeHc75kydnbQvskp9nnAKgqp4ikhKPeqTSzx4CPAFPMrAa4E/iImS0kOnSzA7gxaDsDeMDdl7h7n5ndBrwAhIAH3f2dEbmKERDp7GRiax+RSWGaO4oBjfGLSGo4auJ396sG2bx6iLa7gSX9Xj8HHDbVczzoeH87AFlFmTQ3RMiZmEXuxOwkRyUiEj99c3cI9Vv+AMCksqLojB7d2BWRFKHEP4Smd6NTOUtnH09TbbuGeUQkZejbSEPoeHcLfbkwo+xMutv7KNGMHhFJEerxD8F31lBfBBY6FUBDPSKSMpT4hzChrpX9hc6+njJAxdlEJHUo8Q8i0tPDxH199E1ymltyyZwQYmLxhGSHJSKSEEr8g+ja+R4ZDlmTJ9C8t4PiqXmYDVaBQkRk/FHiH0Td1mAq57QpQXE2je+LSOpQ4h9EY5D4i2fNZ39zt2r0iEhK0XTOQXRUb4RsmFR4FoCmcopISlGPfxDhmt3UFYPZSQAa6hGRlKLEP4gJda20FTr72ovIyDAmleYmOyQRkYRR4h/A+/ooaO6jr8hobuijcGoeoZB+TSKSOpTRBujaVUMoApmT82na006JvrErIilGiX+A+mBGT9706bTWd+obuyKScpT4B2jY9DoABVPPxF01ekQk9Rw18ZvZg2ZWZ2Yb+m37VzPbbGZ/MLOnzKxoiPfuMLO3zWy9ma1NZOAjZf+7G+nOhLyChQCawy8iKSeWHv9DwOIB214CPuDupwFbgf97hPef7+4L3b1yeCGOrkjNHuqKwMPHgUGRevwikmKOmvjd/WWgacC2F929L3j5ClA+ArElRVZdG61FsK8li4KSHLKyQ8kOSUQkoRIxxr8c+PkQ+xx40czWmdnKIx3EzFaa2VozW1tfX5+AsI6dRyIUNPXRWxyiqbZTwzwikpLiSvxm9g9AH/DoEE3OdfczgUuAW83svKGO5e73uXulu1eWlpbGE9aw9dTuISsMGVMK2LdXxdlEJDUNO/Gb2bXApcDfuLsP1sbddwePdcBTwNnDPd9oqNu8DoAJU08i3BtRjR4RSUnDSvxmthj4PLDU3TuGaJNvZgUHngMXARsGaztWNGz4PQC5JQdm9KjHLyKpJ5bpnI8BvwfmmVmNma0AVgEFwEvBVM3vB21nmNlzwVunAr81s7eA14CfufvzI3IVCdL27ib6MmBC/gJAyy2KSGo6allmd79qkM2rh2i7G1gSPN8GnB5XdKMsvKuWuiKgZyq5Ba3k5GclOyQRkYRTPf5+MuvbqS8Cr+/VjB4RSVkq2RBwdwqa+uguyaK5toMSDfOISIpS4g/01dUxoReYMoPujj5N5RSRlKXEH6jb8D8AZE05BVCNHhFJXUr8gfog8WcXKvGLSGrTzd1A27atZBqEJlSQlWPkF2UnOyQRkRGhxB/o3b2XhkLo2V9A8TTHzJIdkojIiNBQTyCzoYOWImPf3k4ttygiKU2JPzCxKUxHySQ6Wnr0jV0RSWlK/EBffS253eClJwCq0SMiqU2JH6h/8xcAZBSfBGhGj4ikNiV+oG7jKwCE8k8iI9OYNCUnyRGJiIwcJX6gdXs1EYCMcorK8sgI6dciIqlLGQ7o2dNAcwF07QtpmEdEUp4SPxBq6KSpJJu2hi7V6BGRlKfE707+vgjtU8pxR1U5RSTlxZT4zexBM6szsw39tpWY2UtmVhU8Fg/x3muDNlXBOr1jSt+ed5nYAX0lcwHN6BGR1Bdrj/8hYPGAbV8AfunuJwK/DF4fwsxKgDuBDxFdaP3OoT4gkqXxrV8BYJMqMIOiqblJjkhEZGTFlPjd/WWgacDmy4CHg+cPAx8b5K0XAy+5e5O7NwMvcfgHSFLt3fQ6ADZhDgVTcsnMCiU5IhGRkRXPGP9Ud98DEDyWDdJmJrCz3+uaYNthzGylma01s7X19fVxhHVsWt7bDkBfb7Fq9IhIWhjpm7uDlbj0wRq6+33uXunulaWlpSMc1h/11DbSnJ9BR3NE4/sikhbiSfx7zWw6QPBYN0ibGmBWv9flwO44zplw1thFXVkpkT7XVE4RSQvxJP5ngQOzdK4FnhmkzQvARWZWHNzUvSjYNjb0dpK/z9k/OfrZpB6/iKSDWKdzPgb8HphnZjVmtgK4G7jQzKqAC4PXmFmlmT0A4O5NwFeB14Ofu4JtY0J410Ym7TfCRXMAVI5ZRNJCTCtwuftVQ+z66CBt1wLX93v9IPDgsKIbYU1vvwyA580hz7KZkKsFyUQk9aX1N3drt7wBgIema5hHRNJGWif+fe+9hwPd7bmayikiaSOtE3933T6aCgoJ97jG90UkbaRv4nfHmnqomzoD0HKLIpI+0jfxt+0hrwXai8sBzegRkfSRttNYIns2MqnN6C04jgk5meRNyk52SCIioyJte/zN7/yODIfIhHKKp+VhNlh1CRGR1JO2iX9P1R8ACIeLNZVTRNJK2ib+fTU19Gbm0deTqcQvImklbcf4O+ta6SsMVt1ScTYRSSPp2ePv6cD29VE/ZTqg4mwikl7SM/E3vUtOSwYdReWEsjIomJyT7IhEREZNWiZ+37uJolajJ6+coql5ZGRoRo+IpI+0TPz7tqwjFIFw5lTV6BGRtJOWN3f3VG8gkpFFuDdP39gVkbSTlom/addusvOmAqYbuyKSdtJvqMedzoZ2WgqmASrOJiLpZ9iJ38zmmdn6fj+tZvbZAW0+YmYt/dp8Kf6Q49S6G2+FxpLpmEFRmRK/iKSXYQ/1uPsWYCGAmYWAXcBTgzT9jbtfOtzzJFzD1uhUzqkzmVSaSygr/f7oERkvent7qampoaurK9mhjBk5OTmUl5eTlZU17GMkaoz/o8C77v5ego43Yry+iqIWozdnOtN0Y1dkTKupqaGgoIA5c+aokCLg7jQ2NlJTU8PcuXOHfZxEdXeXAY8NsW+Rmb1lZj83swVDHcDMVprZWjNbW19fn6CwDtda/SahSAZ9lOjGrsgY19XVxeTJk5X0A2bG5MmT4/4LKO7Eb2bZwFLg8UF2vwEc5+6nA98Bnh7qOO5+n7tXuntlaWlpvGENafe2TXTmlgIZqtEjMg4o6R8qEb+PRPT4LwHecPe9A3e4e6u77w+ePwdkmdmUBJxz2Jr21NGRd2BGj3r8IpJ+EpH4r2KIYR4zm2bBx5OZnR2crzEB5xyennY6mrtpy9dUThGJzfPPP8+8efOoqKjg7rvvPmz/yy+/zJlnnklmZiZPPPFEEiI8dnElfjPLAy4Enuy37SYzuyl4eTmwwczeAr4NLHN3j+eccWmsJtIWorloGhOLJ5Cdk5bfXxORGIXDYW699VZ+/vOfs3HjRh577DE2btx4SJvZs2fz0EMPcfXVVycpymMXV+Zz9w5g8oBt3+/3fBWwKp5zJFRDFRNaMuicNoOp6u2LjCtf+ek7bNzdmtBjnjJjEnf+xZBzTnjttdeoqKjg+OOPB2DZsmU888wznHLKKQfbzJkzB4CMjPEzNXz8RJoAXr+VSS0Z9GaVaXxfRI5q165dzJo16+Dr8vJydu3alcSIEiOtxjr273gbyyjCyVZxNpFx5kg985Ey2Mh0KswySqse/64d1bTn6cauiMSmvLycnTt3HnxdU1PDjBkzkhhRYqRP4o9EaNrbSEe+pnKKSGzOOussqqqq2L59Oz09PaxZs4alS5cmO6y4pU/ib91Fexvsz5tGdl6I3ILh17kQkfSQmZnJqlWruPjii5k/fz5XXnklCxYs4Etf+hLPPvssAK+//jrl5eU8/vjj3HjjjSxYMPpDUscqfcb4G7YSbsukpXAak6dPTIlxOhEZeUuWLGHJkiWHbLvrrrsOPj/rrLOoqakZ7bDikj49/sZqslsz6MqdpvF9EUlr6ZP4G7aS2z6RSGiiZvSISFpLm8TfvnMjhIIbu0r8IpLG0ibx73pvB+150wFN5RSR9JYeib+7jYam/bTnTyUj0ykozkl2RCIiSZMeib+xmvb9WXTkTaNoai6WoRk9IpK+0iPxN1TTtz9E28RpTJlZmOxoRGQcOVpZ5u7ubj7+8Y9TUVHBhz70IXbs2AFAY2Mj559/PhMnTuS2224b5aiPLE0S/1ZCbXn0Zmu5RRGJXSxlmVevXk1xcTHV1dXcfvvtfP7znweii6J/9atf5Rvf+EYyQj+i9PgCV2MVWb0HZvToxq7IuPTzL0Dt24k95rRT4ZLDe/EHxFKW+ZlnnuHLX/4yAJdffjm33XYb7k5+fj5/8id/QnV1dWJjToC06PF37tqCZ6hGj4gcm1jKMvdvk5mZSWFhIY2NyVtoMBZx9/jNbAfQBoSBPnevHLDfgG8BS4AO4Dp3fyPe88YsEmHXrp105J0HFqGwLHfUTi0iCXSEnvlIiaUs83gs3ZyoHv/57r5wYNIPXAKcGPysBO5N0Dlj07KT+jajPW8quZMgFEqLP3JEJAFiKcvcv01fXx8tLS2UlJSMapzHajSy4GXAIx71ClBkZtNH4bxRDVW0dWTRkT+NyTMnjdppRWT8i6Us89KlS3n44YcBeOKJJ7jgggvGfI8/ETd3HXjRzBz4d3e/b8D+mcDOfq9rgm17+jcys5VE/yJg9uzZCQgr0FhFb1s2HWWlzJ89+ejtRUQC/csyh8Nhli9ffrAsc2VlJUuXLmXFihVcc801VFRUUFJSwpo1aw6+f86cObS2ttLT08PTTz/Niy++eMiN4WRJROI/1913m1kZ8JKZbXb3l/vtH+yj77BBseAD4z6AysrKwwfNhqthK5GuaWAh1egRkWN2tLLMOTk5PP7444O+98Cc/rEm7qEed98dPNYBTwFnD2hSA8zq97oc2B3veWPWUEWoLzqyVKLELyISX+I3s3wzKzjwHLgI2DCg2bPAJy3qHKDF3fcwSrprqyCYylk0VXP4RUTiHeqZCjwV3MjIBH7k7s+b2U0A7v594DmiUzmriU7n/FSc54xdVys1Dc105E0jK7uLrAmhUTu1iMhYFVfid/dtwOmDbP9+v+cO3BrPeYatsYr6jmza86YxcbKSvogIpPo3dxuqaenIpiNvKqVzpiQ7GhGRMSHFE/9WOtvLiISymXH8tGRHIyIyJqR24m+sItJbDmi5RREZnuGWZQb453/+ZyoqKpg3bx4vvPDCwe3Lly+nrKyMD3zgA6NxCYdJ7cTfUAXhaE+/RMXZROQYxVOWeePGjaxZs4Z33nmH559/nltuuYVwOAzAddddx/PPPz/q13NA6pZljoTpqXsXz1hChnWSMzEr2RGJSBy+/trX2dy0OaHHPLnkZD5/9ueH3B9PWeZnnnmGZcuWMWHCBObOnUtFRQWvvfYaixYt4rzzzkvql7tSt8e/7312d0Bn3jRy8ruTHY2IjEPxlGWO5b3Jkro9/sZqatujUzknl6Xu55tIujhSz3ykxFOWeSyXa07djNiwlabOyfRl5TO9YvSKgYpI6oinLHMs702WFE78VXR0R6t8lp+UwGqfIpI24inLvHTpUtasWUN3dzfbt2+nqqqKs88eWMosOVI68Yd7ZwJQMmNikoMRkfGof1nm+fPnc+WVVx4sy/zss88CsGLFChobG6moqOCb3/zmwSkna6S1AAAK+0lEQVSfCxYs4Morr+SUU05h8eLFfPe73yUUilYQuOqqq1i0aBFbtmyhvLyc1atXj+p12WDjUMlWWVnpa9euje8g3ziJNa8so2nyIm7+/uIxM7YmIrHbtGkT8+fPT3YYY85gvxczWzfEKoiHSc0ef1cLva17CYemkhVqUdIXEeknNRN/QzW7e7LozJtG7qRwsqMRERlTUjTxb2V3eyHdE4opnKEa/CIi/aVs4q/vPA6AGSdrRo+ISH+pmfgbq+jonQPA3A+clNxYRETGmGEnfjObZWa/NrNNZvaOmX1mkDYfMbMWM1sf/HwpvnBj1FBFX990LNJH0VQVZxMR6S+eHn8fcIe7zwfOAW41s1MGafcbd18Y/Nw1yP7ECvdB0zbCXkamN5ERSs0/akRkdIxEWeahjrlq1SoqKiowMxoaGkbsmoadFd19j7u/ETxvAzYBMxMV2LDte4++vh76sqaSld2W7GhEZBwbibLMRzrmueeeyy9+8QuOO+64Eb2uhBRpM7M5wBnAq4PsXmRmbwG7gb9z93eGOMZKYCXA7Nlx3JBtrKamO4+unClMKVbiF0kVtV/7Gt2bEluWecL8k5n2938/5P6RKMsMDHnMM844I6HXN5S4x0HMbCLwE+Cz7t46YPcbwHHufjrwHeDpoY7j7ve5e6W7V5aWlg4/oIatvNc+CyyD4lmThn8cEUl7I1GWeSyUa46rx29mWUST/qPu/uTA/f0/CNz9OTP7nplNcfeRG7xqqKKx9wQAZi44fsROIyKj60g985EyEmWZI5HIUY850uKZ1WPAamCTu39ziDbTgnaY2dnB+RqHe86YNFTR0TsLPELFGclZz1JEUsNIlGUeC+Wa4xnqORe4Brig33TNJWZ2k5ndFLS5HNgQjPF/G1jmI10VrrGK3vBUsnqbmZCfO6KnEpHUNhJlmWM55kgb9lCPu/8WOOLfJ+6+Clg13HMcs85maK8nTBlZPrJ/WIhI6utfljkcDrN8+fKDZZkrKytZunQpK1as4JprrqGiooKSkhLWrFkDHFqWOTMz85CyzIMdE+Db3/42//Iv/0JtbS2nnXYaS5Ys4YEHHkj4daVWWeadr9N7/0XcX7uGSZkb+MT37kh8cCIyalSWeXAqy9xfw1a2d8/AM7LInZJalyYikiiplR0bq3i/ay4Ak+dOTnIwIiJjU2ol/oYqGvsqADju9HlJDkZEZGxKucTf2TuD7O4WZi84PdnRiIiMSamT+IPibL3hUrJ79xKakJPsiERExqTUSfyhTPzvttKXUUbImpMdjYjImJU6iR/Y351LJJRL5sSuZIciIili+fLllJWV8YEPHHslgHXr1nHqqadSUVHBpz/96YNlHL785S8zc+ZMFi5cyMKFC3nuuecSHfYRpVTi3/ZONQB5ZQkpOioiwnXXXcfzzz8/rPfefPPN3HfffVRVVVFVVXXIcW6//XbWr1/P+vXrWbJkSaLCjUlKZciajduAAiafWJbsUEQkwX7z46007Nyf0GNOmTWRP73yyMuznnfeeYcsrgLw7rvvcuutt1JfX09eXh73338/J5988iFt9uzZQ2trK4sWLQLgk5/8JE8//TSXXHJJQq9hOFKqx79vZyuhvk5mLhhsITARkcRYuXIl3/nOd1i3bh3f+MY3uOWWWw5rs2vXLsrLyw++Hlh+edWqVZx22mksX76c5ubRvS+ZUj3+zn0Z5HfUMnPeR5Idiogk2NF65qNl//79/O53v+OKK644uK27u/uwdkcq6XzzzTfzxS9+ETPji1/8InfccQcPPvjgyAU9QEol/t6eAvJ73ycrTwusi8jIiEQiFBUVsX79+kO2h8NhPvjBDwLRip0333wzNTU1B/f3L788derUg9tvuOEGLr300lGI/I9SZqgnEo6Qt38z2fZeskMRkRQ2adIk5s6dy+OPPw5Ee/ZvvfUWoVDo4M3au+66i+nTp1NQUMArr7yCu/PII49w2WWXAdHx/wOeeuqpYc0YikfKJH7LMOZtfoj84t3JDkVEUshVV13FokWL2LJlC+Xl5axevZpHH32U1atXc/rpp7NgwQKeeeaZQd977733cv3111NRUcEJJ5xw8Mbu5z73OU499VROO+00fv3rX3PPPfeM5iWlzlBPuK+X7EVnc9yHz0l2KCKSQh577LFBt8cyxbOyspINGzYctv0HP/hB3HHFI941dxcD3wJCwAPufveA/ROAR4APEl1y8ePuviOecw4lMyubM1c9NBKHFhFJKfGsuRsCvgtcApwCXGVmA+dRrgCa3b0CuAf4+nDPJyIiiRHPGP/ZQLW7b3P3HmANcNmANpcBDwfPnwA+aqO9nLyIjGtjcZXAZErE7yOexD8T2NnvdU2wbdA27t4HtABaIUVEYpKTk0NjY6OSf8DdaWxsJCcnvurD8YzxD9ZzH/ivE0ubaEOzlcBKgNmzZ8cRloikivLycmpqaqivr092KGNGTk7OId8IHo54En8NMKvf63Jg4FzKA21qzCwTKASaBjuYu98H3AfRxdbjiEtEUkRWVhZz585NdhgpJ56hnteBE81srpllA8uAZwe0eRa4Nnh+OfAr199sIiJJNewev7v3mdltwAtEp3M+6O7vmNldwFp3fxZYDfzAzKqJ9vSXJSJoEREZvrjm8bv7c8BzA7Z9qd/zLuCKge8TEZHksbE48mJm9cBwi+5MARoSGM5Yomsbv1L5+nRtY8Nx7l4aS8MxmfjjYWZr3b0y2XGMBF3b+JXK16drG39SpkibiIjERolfRCTNpGLivy/ZAYwgXdv4lcrXp2sbZ1JujF9ERI4sFXv8IiJyBEr8IiJpJmUSv5ktNrMtZlZtZl9IdjyJZGazzOzXZrbJzN4xs88kO6ZEM7OQmb1pZv+V7FgSycyKzOwJM9sc/PstSnZMiWRmtwf/JzeY2WNmFl/ZyCQyswfNrM7MNvTbVmJmL5lZVfBYnMwYEyUlEn+Mi8KMZ33AHe4+HzgHuDXFrg/gM8CmZAcxAr4FPO/uJwOnk0LXaGYzgU8Dle7+AaKlW8ZzWZaHgMUDtn0B+KW7nwj8Mng97qVE4ie2RWHGLXff4+5vBM/biCaPgWsfjFtmVg78L+CBZMeSSGY2CTiPaM0q3L3H3fclN6qEywRyg+q7eRxeoXfccPeXObx6cP/FpB4GPjaqQY2QVEn8sSwKkxLMbA5wBvBqciNJqP8HfA6IJDuQBDseqAf+IxjGesDM8pMdVKK4+y7gG8D7wB6gxd1fTG5UCTfV3fdAtAMGlCU5noRIlcQf84Iv45mZTQR+AnzW3VuTHU8imNmlQJ27r0t2LCMgEzgTuNfdzwDaSZGhAoBgvPsyYC4wA8g3s08kNyqJRaok/lgWhRnXzCyLaNJ/1N2fTHY8CXQusNTMdhAdorvAzH6Y3JASpgaocfcDf509QfSDIFX8ObDd3evdvRd4EvhwkmNKtL1mNh0geKxLcjwJkSqJP5ZFYcatYIH61cAmd/9msuNJJHf/v+5e7u5ziP67/crdU6LX6O61wE4zmxds+iiwMYkhJdr7wDlmlhf8H/0oKXTzOtB/MalrgWeSGEvCxFWPf6wYalGYJIeVSOcC1wBvm9n6YNvfB+shyNj2t8CjQYdkG/CpJMeTMO7+qpk9AbxBdObZm4zjEgdm9hjwEWCKmdUAdwJ3Az82sxVEP+hSYn0RlWwQEUkzqTLUIyIiMVLiFxFJM0r8IiJpRolfRCTNKPGLiKQZJX4RkTSjxC8ikmb+P5mEbzNkNZUfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e499780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#learn\n",
    "for num, i in enumerate(lr_list):\n",
    "    plt.plot(learn_loss_by_lr[num], label=str(i))\n",
    "plt.title('learn loss')\n",
    "plt.legend()\n",
    "#plt.savefig('gd/learn_loss.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid\n",
    "for num, i in enumerate(lr_list):\n",
    "    plt.plot(epoch_loss_by_lr[num], valid_loss_by_lr[num], label=str(i))\n",
    "plt.title('valid loss')\n",
    "plt.legend()\n",
    "plt.savefig('gd/valid_loss.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "for num, i in enumerate(lr_list):\n",
    "    plt.plot(epoch_loss_by_lr[num], test_loss_by_lr[num], label=str(i))\n",
    "plt.title('test loss')\n",
    "plt.legend()\n",
    "plt.savefig('gd/test_loss.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print((test_loss_by_lr[i])[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'rprop/net_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
